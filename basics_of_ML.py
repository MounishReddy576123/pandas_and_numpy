# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/151dsi7I5l7ze32duyj6emIjMc4a19I3d
"""

!pip install numpy



import numpy as np
arr=np.array([[0,1,2],[3,4,5]],dtype=np.float32)
print(repr(arr))

"""if the array contains multiple data types then the array elements will be casted to the highest order data type 
if the array contains float and integers integers will be type casted to floats
if the array conatins str,int,float everything will be typecasted to string
"""

#Copying the array using referencing 
a=np.array([0,1])
b=np.array([9,8])
c=a
print(c)
c[0]=5
print(a)

#Using the copy() fumction
d=b.copy()
print(repr(d))

#Casting
arr=np.array([1,2,4])
print(arr.dtype)
arr=arr.astype(np.float32)##here the datatype is changed
print(arr.dtype)

"""**Ranged data**"""

arr=np.arange(6)
print(repr(arr))

arr=np.arange(5.)
print(repr(arr))

arr=np.arange(-1,4)
print(repr(arr))

arr=np.arange(-1.5,4,2)#(start,end,step)
print(repr(arr))

#linspace is used to mention how many elements you want in a specified range
arr=np.linspace(5,11,num=4)#(start,end,no.of elements in the range)
print(repr(arr))#here the end value is inclusive

arr=np.linspace(5,22,num=4,endpoint=False)#this will exclude the endpoint
print(arr)

arr=np.linspace(5,11,num=4,dtype=np.int32)
print(repr(arr))

"""**Reshaping Data**"""

arr=np.arange(8)
reshaped_arr=np.reshape(arr,(2,4))
print(repr(reshaped_arr))
print(f"New shape:{reshaped_arr.shape}")

reshaped_arr=np.reshape(arr,(-1,2,2)) #here -1 means python will automatically calculate the value to fit into the size of array
print(repr(reshaped_arr))
print(f"New Shape:{reshaped_arr.shape}")

#flatten the array
arr=np.arange(8)
arr=np.reshape(arr,(2,4))
flattened=arr.flatten()#here 2-D array is flattened into 1D Array
print(repr(arr))
print(repr(flattened))

#transposing the elements
#changing the columns to rows and rows to columns
arr=np.arange(8)
arr=np.reshape(arr,(2,4))
trans=np.transpose(arr)
print(arr.shape)
print(trans.shape)

#Zeroes and Ones
np.zeros(4)#creates an 0 filled array with 4 columns
np.ones((2,4))#creates an 1 filled array with 4 columns and two rows
np.ones((2,4),dtype=np.int32)#creates an integer array

#Matrix Multiplication

arr1=np.array([1,2,3])
arr2=np.array([-3,0,10])
print(np.matmul(arr1,arr2))

#for matmul to work for 2d arrays the no of colums of first array should match with rows of second array
arr3=np.array([[1,2],[3,4],[5,6]])
arr4=np.array([[-1,0,1],[3,2,-4]])
print(repr(np.matmul(arr3,arr4)))
print(repr(np.matmul(arr4,arr3)))

#Random in numpy
print(np.random.randint(5))
print(np.random.randint(5))

print(np.random.randint(3,high=8))

#here we are creating a array of randomly generated integers
random_arr=np.random.randint(-13,high=14,size=(4,4))
print(repr(random_arr))

"""# **UTILITY FUNCTIONS**"""

np.random.seed(1)#it is used when we want the same output to be displayed for every seed we set or for every refresh
print(np.random.randint(10))
arr=np.random.randint(10,high=100,size=(4,4))
print(repr(arr))

np.random.seed(2)#it is used when we want the same output to be displayed for every seed we set or for every refresh
print(np.random.randint(10))
arr=np.random.randint(10,high=100,size=(4,4))
print(repr(arr))

np.random.seed(1)#it is used when we want the same output to be displayed for every seed we set or for every refresh
print(np.random.randint(10))
arr=np.random.randint(10,high=100,size=(4,4))
print(repr(arr))

"""AS you can see the first and third cell produces the same output as the seed number as seen"""

#Array Accessing
arr=np.array([1,2,3,4,5])
print(arr[0])
print(arr[1])
arr1=np.array([[6,3],[0,2]])
print(arr1[-1][0])

#SLICING
arr=np.array([[1,2,3],
              [4,5,6],
              [7,8,9]])
print(arr[:])
print(arr[0:,2])
print(arr[0:3,1])

#Analysis
arr=np.array([[0,72,3],
             [1,3,-60],
             [-3,-2,-4]])
print(arr.min())
print(arr.max())

print(arr.min(axis=0)) #0-column
print(arr.max(axis=1))#1-row

#statistical metrics
arr=np.array([[0,72,3],
             [1,3,-60],
             [-3,-2,4]])
print(np.mean(arr))
print(np.var(arr))
print(np.median(arr))
print(np.median(arr,axis=1))

"""# **INTRODUCTION TO PANDAS**"""

import pandas as pd

"""Pandas Has Two data Structures 


1.   Series
2.   Dataframes


"""

#Pandas Series
g7_pop=pd.Series([35.47,63.951,80.440,60.665,127.061,64.511,378.521])
g7_pop

#Naming the Series
g7_pop.name="Population in millions"
print(g7_pop)
#getting the datatype
print(g7_pop.dtype)
#getting all the values and their datatype
print(repr(g7_pop.values))
print(type(g7_pop.values))

#Setting the Indices for the series
g7_pop.index=['Canada','France','Germany','Italy','Japan','United Kingdom','United States']
g7_pop

#To retrieve the value uisng indices we use iloc method
print(g7_pop.iloc[0])
print(g7_pop.iloc[-1])
#slicing 
print(g7_pop[["Italy","France"]])# it will retrive another series as a numpy array
print(g7_pop["Canada":"France"])# it will retrive another series as a numpy array upper limit is included in series



#Statistical Measures of a series
print(g7_pop.mean())
print(g7_pop.median())
print(g7_pop.std())
print(g7_pop.var())

#Modifying the columns in Series
g7_pop['Canada']=40.5
print(g7_pop)
#Another way of modifying series is
g7_pop.iloc[1]=65.5
#Another way is by boolean indexing
g7_pop[g7_pop<70]=99.9
print(g7_pop)

dict1={"car":["city","ignis","800","verna","venue","Punto"],"brand":["Honda","Maruthi","maruti","Hyundia","Hyundai","Fiat"],"cost":[900000,600000,1000000,800000,950000,7500000],"year":[5,7,10,4,2,6]}

auto=pd.DataFrame(dict1)

auto

#auto.to_csv('automobile.csv')
#auto.to_json('automobiles.json')

#Importing the dataframe
df=pd.read_csv('titanic.csv')
#if we specify header=None then headings wont be read from csv file
df.head()#returns the first 5 rows of the dataframe by default 
#if index is not specified we can specify it by using df.index=[]

#To return rows from last we can use
df.tail()#by default it will return the last 5 rows

#list all the columns
df.columns#lists all the column headings

#to list all the indices
df.index#lists all the row numbers

df.size#Returns the total number of elements

# to Get the shape of the dataframe
df.shape

#counts how many males and females in the ship
df['Sex'].value_counts()

#returns an array containing the unique values in the given column
df["Sex"].unique()

#To get all the info about the dataframe we will use
df.info()

#to describe the dataframes
df.describe()

"""# Accessing columns"""

# to get one column we will use this
df['Sex']

#to get two or more coumns we will use 
df[['Sex',"Name"]]

"""# **Indexing,Selection,Slicing**"""

#to set the index df=df.set_index("Paasenger_id")

#we can get a row in a dataframe using df.loc['key']
#for getting a row with its number we use 
df.iloc[0]

#TO select columns we will use
df['Survived']

#slicing if we have keys then we can slice it by using df.loc[k1:k2]
#for slicing using numerical values
df.iloc[0:3]

df.iloc[1:100:2,1:4]#[row,column]

# if we dont the colum number but we know the column name instead
df.loc[1:5,["Name","Sex"]]

auto['brand']=='Fiat'

#Boolean Indexing
auto[auto['brand']=='Fiat']

auto.loc[auto['brand']=='Fiat',['cost','year']]# to get the specified items from the selected values

auto

#to drop a row using indexes we will use
auto.drop(index=[0,1,2])

# if a row has labels then we can use label to drop that row df.drop(label) or df.drop([labe11:label2])
#to drop columns we will use
auto.drop(columns=['car','cost'],inplace=True)#changes will reflect into original dataframe if we specify inplace=true
#all the changes made are temporary it returns a series

#the original dataframe remains constant
auto

auto=pd.DataFrame(dict1)
auto

#to add a row into an existing data frame
newcar=pd.Series(["Maybeach","Benz",30_00_000,7],index=["car","brand","cost","year"])
auto.loc[len(auto.index)]=newcar
display(auto)#here the changes  made to the dataframe are reflected into the dataframe

#Adding the row
dict2={"car":"Innova","brand":"Toyota","cost":12_00_000,"year":7}
auto.append(dict2,ignore_index=True)# this doesnt change the original dataframe it will be referenced and the output will be shown

#Adding the column in the data frame
mileage=pd.Series([10,7,13,15,4,12,11,8],index=[i for i in range(int(len(auto.index))+1)],name="Mileage")
auto['Mileage']=mileage
print(auto)

#renaming the column names
auto.rename(columns={"car":"Brand"})
#we can rename the rows by calling them with respective indices auto.rename(index={key:value})
#the changes made are not reflected into the original dataframe

auto.rename(columns=str.upper)
# we can do it for rows using index= in place of columns

auto.rename(columns=lambda x:x.lower())

isn_1=auto["car"].isin(["800","city"])
isn_1

auto[isn_1]

start=auto["brand"].str.startswith("H")
auto.loc[start]

ends=auto["brand"].str.endswith("i")
auto.loc[ends,["car","cost"]]

ends=auto["brand"].str.endswith("i")# - indicates the negation of the dataframe
auto.loc[-ends,["car","cost"]]

contains=~auto['brand'].str.contains('o')# ~ also indicates negation
auto.loc[-contains]# here we are again negating to print the brand name that contains o

# checks for nan value in the dataset
isna=auto['car'].isna()
auto.loc[isna]

notna=auto['car'].notna()
auto.loc[notna]

"""# Sorting of **Data**"""

#to sort the data
auto.sort_values("cost",ascending=False)

auto.sort_values(["cost","year"],ascending=[True,False])

auto.columns

auto.columns=[x.lower() for x in auto.columns]

auto

#updating columns
auto["cost"]=auto["cost"].replace({600000:1000000})

auto

# .apply applies to all the values in dataframe
auto["car"]=auto["car"].apply(str.upper)

auto

def price_change(price):
  return price/10

auto["cost"].apply(price_change)

auto["cost"].apply(lambda x:x*10)

auto["car"].replace({"city":"city_xz","ignis":"swift"})

"""# **Updating Rows**"""

auto.loc[2,["car","price"]]=["DESIRE",600000]

auto

"""# **Aggregation of data**"""

groups=df.groupby(['Sex','Survived'])

groups.mean()

groups.size()

groups.count()

"""# **Cleaning of Data**"""

dict_3={"car":["city","ignis",np.nan,"Verna","Venue","Punto",np.nan],"brand":["Honda","maruti","Maruti","Hyundia",np.nan,"Fiat","Venue"]
       ,"cost":[900000,600000,np.nan,800000,950000,750000,np.nan,],"year":[5,7,10,np.nan,np.nan,6,np.nan] }

auto=pd.DataFrame(dict_3)

#to count the number of null values in each column of a dataframe
auto.isnull().sum()

#here we are dropping null values
#axis=0 or 1  how specifies any or all
# to select particular column we use subset
auto.dropna(axis=0,how="all",subset=["car"])
auto

#to fill the null values
auto["cost"].fillna(0,inplace=True)

auto